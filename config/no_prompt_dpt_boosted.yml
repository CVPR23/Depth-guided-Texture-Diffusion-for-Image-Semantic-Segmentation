_base_: 
  - base/visualization/clearml.yml

# Setup
env_cfg: {}
train_cfg:
  by_epoch: &by_epoch True
  max_epochs: &max_epochs 80
  val_interval: 80
val_cfg: {}
find_unused_parameters: True

# Dataset and loaders
train_dataloader:
  batch_size: 10
  num_workers: 4 
  pin_memory: true
  persistent_workers: true
  dataset: 
    type: COD10K_CAMO_TRAIN
    data_dir: /root/autodl-tmp/dataset/cod_train
    depth_dir: Depth_boost_dpt_nyu/boosted/
    split: train
  sampler:
    type: DefaultSampler
    shuffle: True
val_dataloader:
  batch_size: 1
  num_workers: 4
  dataset: 
    type: COD10K_TEST
    data_dir: /root/autodl-tmp/dataset/cod10k_test
    depth_dir: Depth_boost_dpt_nyu/boosted/
    split: val
  sampler:
    type: DefaultSampler
    shuffle: False

# Model
model:
  type: DQnet
  win_size: 3
  filter_ratio: 0.9
  using_sam: True
  using_depth: True
  finetune: True
  binary_thresh: 0.2
  pretrain_sam: output/train_60epo_lr_1e-4/epoch_60.pth
  head: 
    type: mmseg.models.decode_heads.SegformerHead
    in_channels: [256, 512, 1024, 2048]
    channels: 256
    num_classes: 1
    in_index: [0,1,2,3]
# Optimization
optim_wrapper:
  # constructor: LayerDecayOptimWrapperConstructor
  type: AmpOptimWrapper
  # paramwise_cfg: 
  #   decay_factor: 0.9
    #0.9
  optimizer:
    type: AdamW
    lr: 0.0005
    weight_decay: 0.1
  paramwise_cfg: 
    bypass_duplicate: True
    custom_keys: 
      depth_backbone:
        lr_mult: 0 
      depth_head:
        lr_mult: 0 
      hitnet.backbone:
        lr_mult: 0.1
      hitnet.backbone.depth_generator:
        lr_mult: 2
      hitnet.backbone.cross:
        lr_mult: 2
      depth_head:
        lr_mult: 0 
      norm0:
        lr_mult: 0 
      norm1:
        lr_mult: 0 
      norm2:
        lr_mult: 0 


      # sam.image_encoder:
      #   lr_mult: 0
      # sam.image_encoder.prompt_generator:
      #   lr_mult: 0
      # sam.image_encoder.depth_generator:
      #   lr_mult: 1
      # # sam.prompt_encoder:
      # #   lr_mult: 1
      # sam.mask_decoder:
      #   lr_mult: 1
      # depth_estimator:
      #   lr_mult: 0


  # clip_grad:
  #   type: value
  #   clip_value: 0.5

param_scheduler:
  type: CosineAnnealingLR
  # power: 0.9
  by_epoch: *by_epoch
  T_max: *max_epochs
  # convert_to_iter_based: True
  # type: PolyLR
  # power: 0.9
  # verbose: True

# Evaluation
val_evaluator:
  - type: Emeasure
  - type: Fmeasure
  - type: Smeasure
  - type: WeightedFmeasure
  - type: MAE

# Hooks
default_hooks:
  logger:
    type: LoggerHook
    interval: 20
    ignore_last: false
  checkpoint:
    type: CheckpointHook
    by_epoch: *by_epoch
    interval: 20

custom_hooks:
  -
    type: PretrainInitHook
